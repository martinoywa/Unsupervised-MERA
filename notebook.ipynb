{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c45e0d9-7edd-4eb0-ac3c-e941d9222285",
   "metadata": {},
   "source": [
    "# Unsupervised MERA\n",
    "\n",
    "- MERA stands for Music Emotion Recognition Algorithm which was built to classify emotions from music based on both a song's lyrics and audio. The algorithm was built on the concepts of Valence and Arousal in music, which represent the spectrum of positive to negative emotions and low to high energy respectively, and Quadrants, which are representations of combinations of Valence and Arousal depending on their sign (-/+). This algorithm was a supervised task as we had a target variable.\n",
    "\n",
    "- In this notebook, I'll be experimenting whether it's also possible to identify the target lables / Quadrants using unsupervied learning techniques. Since the dataset I'll be using for the experiment already has the expected outcome / Quadrants, I should be able to evaluate how well unsupervied techniques can be used in identitying the lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8a0368a-a377-4f01-beab-70919a2df713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d62a9a3-887d-47b0-9b0e-976e6a86cda0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2f778a-82e4-47d7-8b24-d61c7b975b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# download data\n",
    "!wget https://raw.githubusercontent.com/martinoywa/MERA/master/data/train.csv\n",
    "!wget https://raw.githubusercontent.com/martinoywa/MERA/master/data/test.csv\n",
    "!wget https://raw.githubusercontent.com/martinoywa/MERA/master/data/validation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "634277ff-1e3d-4da5-8f10-b56d93ff911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>quadrant</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213754</th>\n",
       "      <th>-0.682725</th>\n",
       "      <th>0.316758</th>\n",
       "      <th>Dark Tranquillity</th>\n",
       "      <th>Insanity's Crescendo</th>\n",
       "      <td>1</td>\n",
       "      <td>Gently, hold our heads Gently, hold our heads ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216752</th>\n",
       "      <th>-1.400403</th>\n",
       "      <th>1.538229</th>\n",
       "      <th>Anorexia Nervosa</th>\n",
       "      <th>Stabat mater dolorosa</th>\n",
       "      <td>1</td>\n",
       "      <td>We are the Sun We are the dead stars We are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254391</th>\n",
       "      <th>0.815393</th>\n",
       "      <th>0.662457</th>\n",
       "      <th>Uniting Nations</th>\n",
       "      <th>Out Of Touch</th>\n",
       "      <td>0</td>\n",
       "      <td>You're out of touch, I'm out of time But I'm o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266313</th>\n",
       "      <th>1.257460</th>\n",
       "      <th>1.086515</th>\n",
       "      <th>The Walkmen</th>\n",
       "      <th>Brandy alexander</th>\n",
       "      <td>0</td>\n",
       "      <td>Finally close the door You'd left open wide Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283306</th>\n",
       "      <th>0.373325</th>\n",
       "      <th>-0.923151</th>\n",
       "      <th>Duke Ellington</th>\n",
       "      <th>Caravan</th>\n",
       "      <td>3</td>\n",
       "      <td>Night and stars above that shine so bright The...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    quadrant  \\\n",
       "213754 -0.682725  0.316758 Dark Tranquillity Insanity's Crescendo          1   \n",
       "216752 -1.400403  1.538229 Anorexia Nervosa  Stabat mater dolorosa         1   \n",
       "254391  0.815393  0.662457 Uniting Nations   Out Of Touch                  0   \n",
       "266313  1.257460  1.086515 The Walkmen       Brandy alexander              0   \n",
       "283306  0.373325 -0.923151 Duke Ellington    Caravan                       3   \n",
       "\n",
       "                                                                                                               lyrics  \n",
       "213754 -0.682725  0.316758 Dark Tranquillity Insanity's Crescendo   Gently, hold our heads Gently, hold our heads ...  \n",
       "216752 -1.400403  1.538229 Anorexia Nervosa  Stabat mater dolorosa  We are the Sun We are the dead stars We are th...  \n",
       "254391  0.815393  0.662457 Uniting Nations   Out Of Touch           You're out of touch, I'm out of time But I'm o...  \n",
       "266313  1.257460  1.086515 The Walkmen       Brandy alexander       Finally close the door You'd left open wide Lo...  \n",
       "283306  0.373325 -0.923151 Duke Ellington    Caravan                Night and stars above that shine so bright The...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"train.csv\", header=None, names=[\"quadrant\", \"lyrics\"], skiprows=1)\n",
    "test = pd.read_csv(\"test.csv\", header=None, names=[\"quadrant\", \"lyrics\"], skiprows=1)\n",
    "valid = pd.read_csv(\"validation.csv\", header=None, names=[\"quadrant\", \"lyrics\"], skiprows=1)\n",
    "\n",
    "# merge the data\n",
    "df = pd.concat([train, test, valid])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a46ace0e-08d7-43c3-867c-6606926a6ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>quadrant</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213754</th>\n",
       "      <th>-0.682725</th>\n",
       "      <th>0.316758</th>\n",
       "      <th>Dark Tranquillity</th>\n",
       "      <th>Insanity's Crescendo</th>\n",
       "      <td>1</td>\n",
       "      <td>gently  hold our heads gently  hold our heads ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216752</th>\n",
       "      <th>-1.400403</th>\n",
       "      <th>1.538229</th>\n",
       "      <th>Anorexia Nervosa</th>\n",
       "      <th>Stabat mater dolorosa</th>\n",
       "      <td>1</td>\n",
       "      <td>we are the sun we are the dead stars we are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254391</th>\n",
       "      <th>0.815393</th>\n",
       "      <th>0.662457</th>\n",
       "      <th>Uniting Nations</th>\n",
       "      <th>Out Of Touch</th>\n",
       "      <td>0</td>\n",
       "      <td>you are out of touch  i am out of time but i a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266313</th>\n",
       "      <th>1.257460</th>\n",
       "      <th>1.086515</th>\n",
       "      <th>The Walkmen</th>\n",
       "      <th>Brandy alexander</th>\n",
       "      <td>0</td>\n",
       "      <td>finally close the door you would left open wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283306</th>\n",
       "      <th>0.373325</th>\n",
       "      <th>-0.923151</th>\n",
       "      <th>Duke Ellington</th>\n",
       "      <th>Caravan</th>\n",
       "      <td>3</td>\n",
       "      <td>night and stars above that shine so bright the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    quadrant  \\\n",
       "213754 -0.682725  0.316758 Dark Tranquillity Insanity's Crescendo          1   \n",
       "216752 -1.400403  1.538229 Anorexia Nervosa  Stabat mater dolorosa         1   \n",
       "254391  0.815393  0.662457 Uniting Nations   Out Of Touch                  0   \n",
       "266313  1.257460  1.086515 The Walkmen       Brandy alexander              0   \n",
       "283306  0.373325 -0.923151 Duke Ellington    Caravan                       3   \n",
       "\n",
       "                                                                                                               lyrics  \n",
       "213754 -0.682725  0.316758 Dark Tranquillity Insanity's Crescendo   gently  hold our heads gently  hold our heads ...  \n",
       "216752 -1.400403  1.538229 Anorexia Nervosa  Stabat mater dolorosa  we are the sun we are the dead stars we are th...  \n",
       "254391  0.815393  0.662457 Uniting Nations   Out Of Touch           you are out of touch  i am out of time but i a...  \n",
       "266313  1.257460  1.086515 The Walkmen       Brandy alexander       finally close the door you would left open wid...  \n",
       "283306  0.373325 -0.923151 Duke Ellington    Caravan                night and stars above that shine so bright the...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess lyrics\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    text = text.lower() # lower text\n",
    "    text = replace_contractions(text) # remove contactions\n",
    "    text = \"\".join(\"\".join(text).replace(\"\\n\", \" \").replace(\"\\r\", \" \")) # remove \\n and \\r\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace symbols with space\n",
    "    text = re.sub(r'[0-9]+', '', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # replace bad characters with nothing\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df[\"lyrics\"] = df[\"lyrics\"].apply(text_preprocessing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "571afe73-b189-4abb-a945-0f8bee4787ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract quadrants and lyrics\n",
    "quadrants = df[\"quadrant\"]\n",
    "lyrics = df[\"lyrics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faf495-e166-4028-8802-b706f6c5a885",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating the word frequency array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e84237d-57d9-44ff-b29c-2d57f5dd0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "csr_array = tfidf.fit_transform(lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab07f50b-ea3e-4488-87f3-e89ce3e0f8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the ompressed sparse row array\n",
    "csr_array.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1124a5a0-987d-4d03-8b40-91b9f9aca775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['_______', '__________', '___________', '____________',\n",
       "       '_______________', '_______________________________', 'aa', 'aaa',\n",
       "       'aaaa', 'aaaaa', 'aaaaaa', 'aaaaaaa', 'aaaaaaaa',\n",
       "       'aaaaaaaaaaaaaaaaaaaaaaaaah', 'aaaaaaaaaaaaaaaaaaaw',\n",
       "       'aaaaaaaaaaaaaaaaah', 'aaaaaaaaaaah', 'aaaaaaaaaah', 'aaaaaaaah',\n",
       "       'aaaaaaah', 'aaaaaaahhhh', 'aaaaaah', 'aaaaaahhhh', 'aaaaaahhhhh',\n",
       "       'aaaaah', 'aaaaahhaaaaahhaaaaahhaaaaahhaaaaahh', 'aaaaahhhhh',\n",
       "       'aaaah', 'aaaahhaaaaahh', 'aaaahhhh', 'aaaahhhhhhh',\n",
       "       'aaaahhhhhhhhhh', 'aaaant', 'aaagain', 'aaah', 'aaahaaa',\n",
       "       'aaahaaahaahaa', 'aaahh', 'aaahhh', 'aaahstop', 'aaand', 'aaare',\n",
       "       'aaate', 'aable', 'aacacia', 'aadam', 'aagg', 'aaghhhhhhhh', 'aah',\n",
       "       'aahaah', 'aahaahaah', 'aahaahaahaaa', 'aahh', 'aahhh',\n",
       "       'aahhhhhhhhhhhhhhhhh', 'aaight', 'aail', 'aaja', 'aakash', 'aale',\n",
       "       'aalegra', 'aalike', 'aaliyah', 'aaliyahs', 'aall', 'aalright',\n",
       "       'aan', 'aanything', 'aao', 'aaooaaooh', 'aaow', 'aap', 'aarb',\n",
       "       'aarbi', 'aardvark', 'aardvarks', 'aare', 'aaron', 'aarons',\n",
       "       'aasdocktor', 'aasgaars', 'aaw', 'aay', 'aayyeah', 'ab', 'abab',\n",
       "       'ababababa', 'ababwa', 'abacinate', 'aback', 'abacus', 'abad',\n",
       "       'abandom', 'abandon', 'abandoned', 'abandonin', 'abandoning',\n",
       "       'abandonment', 'abandonne', 'abandons'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the feature names\n",
    "words = tfidf.get_feature_names_out()\n",
    "words[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e01482-8114-4692-bc79-92e0ec2187f5",
   "metadata": {},
   "source": [
    "Some of the data looks like a bunch of noise as they are not necessarily words. I'll leave them around for now, but these are probably worth removing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95af7253-7cfa-470b-88dd-3e9db24b7e57",
   "metadata": {},
   "source": [
    "## Dimesionality reduction and clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c0713b7-aed6-4511-b0ca-e82ab8cb3028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TruncatedSVD is able to perform PCA on sparse arrays in csr_matrix format, such as word-frequency arrays\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "kmeans = KMeans(n_clusters=4) # 4 clusters one for each quadrant\n",
    "pipeline = make_pipeline(svd, kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "544e0bc8-89b5-40e5-91e8-50e7fecacef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('truncatedsvd', TruncatedSVD(n_components=50)),\n",
       "                ('kmeans', KMeans(n_clusters=4))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the pipeline\n",
    "pipeline.fit(csr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0dcc4de-3876-439a-8406-213a4f0e0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cluster labels\n",
    "labels = pipeline.predict(csr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b672e1-990e-48d8-b534-7d17335f89dc",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a812aac-4065-45b6-a1a3-92b5f458b3a9",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c23f0-6260-446b-a39f-ea81fe9bea17",
   "metadata": {},
   "source": [
    "- Other processes we can try is clustering artist, this might help us identify commonalities between them such as genres or even writing styles,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c992342-c20c-490b-a723-186b0eef4af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
