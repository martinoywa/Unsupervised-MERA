{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c45e0d9-7edd-4eb0-ac3c-e941d9222285",
   "metadata": {},
   "source": [
    "# Unsupervised MERA\n",
    "\n",
    "- MERA stands for Music Emotion Recognition Algorithm which was built to classify emotions from music based on both a song's lyrics and audio. The algorithm was built on the concepts of Valence and Arousal in music, which represent the spectrum of positive to negative emotions and low to high energy respectively, and Quadrants, which are representations of combinations of Valence and Arousal depending on their sign (-/+). This algorithm was a supervised task as we had a target variable.\n",
    "\n",
    "- In this notebook, I'll be experimenting whether it's also possible to identify the target lables / Quadrants using unsupervied learning techniques. Since the dataset I'll be using for the experiment already has the expected outcome / Quadrants, I should be able to evaluate how well unsupervied techniques can be used in identitying the lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0368a-a377-4f01-beab-70919a2df713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
